{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b320d2-7477-4690-bb4e-a594b93ae104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root dir is: /scratch/6983143.1.academic-gpu/tmp5zyg7zwb\n",
      "case7\n",
      "case3\n",
      "case4\n",
      "case5\n",
      "case8\n",
      "case1\n",
      "case2\n",
      "case6\n",
      "Image dataset shape: (40, 18, 128, 128)\n",
      "Left Mask dataset shape: (40, 128, 128)\n",
      "Right Mask dataset shape: (40, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "AsDiscrete,\n",
    "AsDiscreted,\n",
    "EnsureChannelFirstd,\n",
    "Compose,\n",
    "CropForegroundd,\n",
    "LoadImaged,\n",
    "Orientationd,\n",
    "Spacingd,\n",
    "Invertd,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(f\"root dir is: {root_dir}\")\n",
    "\n",
    "# Define paths to the folders containing images and masks\n",
    "data_folder = \"/projectnb/ec500kb/projects/Project_3/Maolin/Data/\"\n",
    "masks_folder = \"/projectnb/ec500kb/projects/Project_3/Maolin/Data/\"  # Same as the image folder\n",
    "\n",
    "# Create empty lists to store image and mask data\n",
    "image_dataset = []\n",
    "left_mask_dataset = []\n",
    "right_mask_dataset = []\n",
    "\n",
    "\n",
    "# Iterate through image files and import them\n",
    "for images_folder in os.listdir(data_folder):\n",
    "    if os.path.isdir(os.path.join(data_folder, images_folder)):\n",
    "        print(images_folder)\n",
    "        for filename in os.listdir(os.path.join(data_folder, images_folder)):\n",
    "            if filename.endswith('.nrrd'):\n",
    "                # Construct full path to the image file\n",
    "                raw_img_path = os.path.join(data_folder, images_folder, filename)\n",
    "\n",
    "                # Read in image\n",
    "                raw_img_sitk = sitk.ReadImage(raw_img_path, sitk.sitkFloat32)\n",
    "\n",
    "                # Convert the array\n",
    "                raw_img_sitk_arr = sitk.GetArrayFromImage(raw_img_sitk)\n",
    "\n",
    "                # Add image data to list\n",
    "                image_dataset.append(raw_img_sitk_arr)\n",
    "\n",
    "                # Iterate through each mask file\n",
    "                for side in [\"left\", \"right\"]:  # It is done this way so that I import 5 copies of each mask. since the same mask is used for each image volume\n",
    "                    mask_filename = f\"svr_{side}KidneyMask2.nii.gz\"\n",
    "                    mask_path = os.path.join(masks_folder, images_folder, mask_filename)\n",
    "\n",
    "                    # Read in mask\n",
    "                    raw_mask_sitk = sitk.ReadImage(mask_path, sitk.sitkFloat32)\n",
    "\n",
    "                    # Convert the array\n",
    "                    mask_arr = sitk.GetArrayFromImage(raw_mask_sitk)\n",
    "\n",
    "                    if side == \"left\":\n",
    "                        left_mask_dataset.append(mask_arr[0])\n",
    "                    elif side == \"right\":\n",
    "                        right_mask_dataset.append(mask_arr[0])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "image_dataset = np.array(image_dataset)\n",
    "left_mask_dataset = np.array(left_mask_dataset)\n",
    "right_mask_dataset = np.array(right_mask_dataset)\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"Image dataset shape:\", image_dataset.shape)  # samples, slices, slice_x, slice_y\n",
    "print(\"Left Mask dataset shape:\", left_mask_dataset.shape)\n",
    "print(\"Right Mask dataset shape:\", right_mask_dataset.shape)\n",
    "\n",
    "combined_masks = []\n",
    "\n",
    "for i in range(len(left_mask_dataset)):\n",
    "    combined_masks.append(left_mask_dataset[i] + right_mask_dataset[i])\n",
    "\n",
    "combined_masks = np.array(combined_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b59e0c88-8fd8-4cbf-bf6c-76c96d01fcd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bounding_box_edges(mask):\n",
    "    labeled_mask = label(mask)\n",
    "    \n",
    "    bboxes = []\n",
    "    if labeled_mask.max() == 0:\n",
    "        return mask\n",
    "    \n",
    "    border = np.zeros_like(mask)\n",
    "    \n",
    "    for region in regionprops(labeled_mask):\n",
    "        min_row, min_col, max_row, max_col = region.bbox\n",
    "        # Fill in bounding box edges\n",
    "        border[min_row:min_row+2, min_col:max_col+1] = 1  # top edge\n",
    "        border[max_row-1:max_row+1, min_col:max_col+1] = 1  # bottom edge\n",
    "        border[min_row:max_row+1, min_col:min_col+2] = 1  # left edge\n",
    "        border[min_row:max_row+1, max_col-1:max_col+1] = 1  # right edge\n",
    "    \n",
    "    return border\n",
    "\n",
    "def calculate_iou(bbox1, bbox2):\n",
    "    # Calculate intersection\n",
    "    intersection = np.logical_and(bbox1, bbox2)\n",
    "\n",
    "    # Calculate union\n",
    "    union = np.logical_or(bbox1, bbox2)\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e88a96-c9df-469e-b9b8-ea913a7bc821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 128, 128)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(combined_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cb8454-68aa-4993-853a-4273c77739e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define the volume U-Net Model\n",
    "\"\"\"\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Define the UNet model\n",
    "class MyUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyUNet, self).__init__()\n",
    "        self.unet = UNet(\n",
    "            spatial_dims=2,  # Set spatial dimensions to 2 for 2D data\n",
    "            in_channels=18,  # Input volume with 18 channels\n",
    "            out_channels=1,  # Single channel output mask\n",
    "            channels=(16, 32, 64, 128, 256), #, 256 # Depth of 5\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,  # Number of residual units\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.unet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ad92ff5-ca79-4d9e-be15-abcc79731e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch [100/1000], Loss: 0.5337\n",
      "Epoch [200/1000], Loss: 0.3131\n",
      "Epoch [300/1000], Loss: 0.1928\n",
      "Epoch [400/1000], Loss: 0.1118\n",
      "Epoch [500/1000], Loss: 0.0669\n",
      "Epoch [600/1000], Loss: 0.0434\n",
      "Epoch [700/1000], Loss: 0.0301\n",
      "Epoch [800/1000], Loss: 0.0223\n",
      "Epoch [900/1000], Loss: 0.0170\n",
      "Epoch [1000/1000], Loss: 0.0135\n",
      "Test Loss: 0.3164\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/6983143.1.academic-gpu/ipykernel_2310558/1111044313.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = torch.tensor(thresholded_masks[idx]).unsqueeze(0).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.6012\n",
      "Epoch [200/1000], Loss: 0.3047\n",
      "Epoch [300/1000], Loss: 0.1716\n",
      "Epoch [400/1000], Loss: 0.1153\n",
      "Epoch [500/1000], Loss: 0.0837\n",
      "Epoch [600/1000], Loss: 0.0632\n",
      "Epoch [700/1000], Loss: 0.0497\n",
      "Epoch [800/1000], Loss: 0.0406\n",
      "Epoch [900/1000], Loss: 0.0339\n",
      "Epoch [1000/1000], Loss: 0.0287\n",
      "Test Loss: 0.3433\n",
      "2\n",
      "Epoch [100/1000], Loss: 0.5770\n",
      "Epoch [200/1000], Loss: 0.3572\n",
      "Epoch [300/1000], Loss: 0.2354\n",
      "Epoch [400/1000], Loss: 0.1453\n",
      "Epoch [500/1000], Loss: 0.0884\n",
      "Epoch [600/1000], Loss: 0.0569\n",
      "Epoch [700/1000], Loss: 0.0392\n",
      "Epoch [800/1000], Loss: 0.0285\n",
      "Epoch [900/1000], Loss: 0.0216\n",
      "Epoch [1000/1000], Loss: 0.0170\n",
      "Test Loss: 0.2033\n",
      "3\n",
      "Epoch [100/1000], Loss: 0.5205\n",
      "Epoch [200/1000], Loss: 0.2950\n",
      "Epoch [300/1000], Loss: 0.1786\n",
      "Epoch [400/1000], Loss: 0.1052\n",
      "Epoch [500/1000], Loss: 0.0651\n",
      "Epoch [600/1000], Loss: 0.0430\n",
      "Epoch [700/1000], Loss: 0.0302\n",
      "Epoch [800/1000], Loss: 0.0224\n",
      "Epoch [900/1000], Loss: 0.0173\n",
      "Epoch [1000/1000], Loss: 0.0138\n",
      "Test Loss: 0.2690\n",
      "4\n",
      "Epoch [100/1000], Loss: 0.5482\n",
      "Epoch [200/1000], Loss: 0.3510\n",
      "Epoch [300/1000], Loss: 0.2059\n",
      "Epoch [400/1000], Loss: 0.1109\n",
      "Epoch [500/1000], Loss: 0.0633\n",
      "Epoch [600/1000], Loss: 0.0404\n",
      "Epoch [700/1000], Loss: 0.0278\n",
      "Epoch [800/1000], Loss: 0.0205\n",
      "Epoch [900/1000], Loss: 0.0157\n",
      "Epoch [1000/1000], Loss: 0.0125\n",
      "Test Loss: 0.2191\n",
      "5\n",
      "Epoch [100/1000], Loss: 0.5470\n",
      "Epoch [200/1000], Loss: 0.3469\n",
      "Epoch [300/1000], Loss: 0.2274\n",
      "Epoch [400/1000], Loss: 0.1360\n",
      "Epoch [500/1000], Loss: 0.0831\n",
      "Epoch [600/1000], Loss: 0.0529\n",
      "Epoch [700/1000], Loss: 0.0363\n",
      "Epoch [800/1000], Loss: 0.0266\n",
      "Epoch [900/1000], Loss: 0.0203\n",
      "Epoch [1000/1000], Loss: 0.0161\n",
      "Test Loss: 0.2822\n",
      "6\n",
      "Epoch [100/1000], Loss: 0.5226\n",
      "Epoch [200/1000], Loss: 0.3361\n",
      "Epoch [300/1000], Loss: 0.2078\n",
      "Epoch [400/1000], Loss: 0.1171\n",
      "Epoch [500/1000], Loss: 0.0684\n",
      "Epoch [600/1000], Loss: 0.0440\n",
      "Epoch [700/1000], Loss: 0.0304\n",
      "Epoch [800/1000], Loss: 0.0222\n",
      "Epoch [900/1000], Loss: 0.0169\n",
      "Epoch [1000/1000], Loss: 0.0134\n",
      "Test Loss: 0.1455\n",
      "7\n",
      "Epoch [100/1000], Loss: 0.5414\n",
      "Epoch [200/1000], Loss: 0.3281\n",
      "Epoch [300/1000], Loss: 0.1987\n",
      "Epoch [400/1000], Loss: 0.1122\n",
      "Epoch [500/1000], Loss: 0.0666\n",
      "Epoch [600/1000], Loss: 0.0430\n",
      "Epoch [700/1000], Loss: 0.0300\n",
      "Epoch [800/1000], Loss: 0.0220\n",
      "Epoch [900/1000], Loss: 0.0169\n",
      "Epoch [1000/1000], Loss: 0.0134\n",
      "Test Loss: 0.1583\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loop to do every possible 7/1 split in the participant population\n",
    "\"\"\"\n",
    "MEAN_TEST_LOSS = []\n",
    "MEAN_DICE = []\n",
    "MEAN_IOU = []\n",
    "\n",
    "# Use each participant as the test once\n",
    "for test_idx in range(8):\n",
    "    print(test_idx)\n",
    "    big_loss = []\n",
    "\n",
    "    # Define a new model for each run through\n",
    "    model = MyUNet().to(device)\n",
    "\n",
    "    # Define Dice Loss\n",
    "    criterion = DiceLoss(sigmoid=True)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Create the training test split\n",
    "    test_start = test_idx * 5\n",
    "    test_end = (test_idx + 1) * 5\n",
    "\n",
    "    # Define training and testing data\n",
    "    X_train = np.concatenate([image_dataset[:test_start], image_dataset[test_end:]])\n",
    "    y_train = np.concatenate([combined_masks[:test_start], combined_masks[test_end:]])\n",
    "    X_test = image_dataset[test_start:test_end]\n",
    "    y_test = combined_masks[test_start:test_end]\n",
    "    \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)  # add channel dimension\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)  # add channel dimension\n",
    "\n",
    "    # Train the model on this training set\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to train mode\n",
    "        model.train()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_train_tensor)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        big_loss.append(loss.item())\n",
    "        # Print loss every 10 epochs\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # After training, predict on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(outputs, y_test_tensor)\n",
    "        print(f'Test Loss: {test_loss.item():.4f}')\n",
    "        test_masks = [thing.cpu() for thing in outputs]\n",
    "\n",
    "    # Binarize the masks\n",
    "    thresholded_masks = []\n",
    "\n",
    "    for mask in test_masks:\n",
    "        # Calculate intensity range\n",
    "        min_intensity = torch.min(mask)\n",
    "        max_intensity = torch.max(mask)\n",
    "        intensity_range = max_intensity - min_intensity\n",
    "\n",
    "        # Calculate 50% mark\n",
    "        threshold = min_intensity + 0.5 * intensity_range\n",
    "\n",
    "        # Threshold the mask\n",
    "        thresholded_mask = torch.where(mask >= threshold, torch.tensor(1), torch.tensor(0))\n",
    "\n",
    "        # Append the thresholded mask to the list\n",
    "        thresholded_masks.append(thresholded_mask)\n",
    "    \n",
    "    dice_metric = DiceMetric(include_background=True)\n",
    "\n",
    "    # Calculate Dice score\n",
    "    test_dice = []\n",
    "\n",
    "    for idx in range(len(test_masks)):\n",
    "        # Get proper shapes for dice score function\n",
    "        y_true = torch.tensor(y_test[idx]).unsqueeze(0).unsqueeze(0)\n",
    "        y_pred = torch.tensor(thresholded_masks[idx]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Calculate the dice score :P\n",
    "        dice = dice_metric(y_pred, y_true)\n",
    "\n",
    "        # append to the list of dice\n",
    "        test_dice.append(float(dice))\n",
    "\n",
    "    # Calculate mean dice\n",
    "    MEAN_DICE.append(np.mean(test_dice))\n",
    "\n",
    "    \n",
    "    # Calculate the IOU\n",
    "    # Create bounding box coordinates\n",
    "    mask_array = []\n",
    "    bboxes = []\n",
    "    for i in range(len(y_test)):\n",
    "        mask_array.append(thresholded_masks[i][0].numpy())\n",
    "        bboxes.append(bounding_box_edges(mask_array[i]))\n",
    "\n",
    "    IOU_storage = []\n",
    "    for i in range(len(mask_array)):\n",
    "        IOU_storage.append(calculate_iou(mask_array[i], y_test[i]))\n",
    "\n",
    "    # Calculate mean IOU\n",
    "    MEAN_IOU.append(np.mean(IOU_storage))\n",
    "\n",
    "    # Calculate test loss\n",
    "    test_loss = criterion(outputs, y_test_tensor)\n",
    "    MEAN_TEST_LOSS.append(test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee8527cf-b9f4-4ebc-ab6e-053736dec778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4628210102221385, 0.49725355650549624, 0.5913396760982835, 0.5862151167271445, 0.7374472674422631, 0.5552064916088438, 0.7635396674521673, 0.7405907226569177]\n"
     ]
    }
   ],
   "source": [
    "#print(MEAN_TEST_LOSS)\n",
    "#print(MEAN_DICE)\n",
    "print(MEAN_IOU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
